import{_ as t,c as i,d as o,o as n}from"./app-2tArAyrn.js";const a={};function r(s,e){return n(),i("div",null,e[0]||(e[0]=[o('<div class="hint-container note"><p class="hint-container-title">Brief: This work is implemented for end-to-end deep reinforcement learning Sim2Real applied on quadrotors. To this end, we develop a series of toolkits including hardware and software, to facilitate RL based methods deployed in reality, especially outside the laboratory.</p></div><div><video width="900" controls><source src="https://emnavi-doc-img.oss-cn-beijing.aliyuncs.com/emnavi_video/airgym/final3.1_pressed.mp4" type="video/mp4"></video></div><h2 id="abstract" tabindex="-1"><a class="header-anchor" href="#abstract"><span><strong>Abstract</strong></span></a></h2><div class="custom-line-height"> The deployment of end-to-end learning-based methods for quadrotor control in unstructured outdoor environments poses significant challenges, including the scarcity of reliable real-world observations, stringent requirements for onboard real-time inference, and the sim-to-real gap inherent to dynamic, noisy settings. Current works have made a great breakthrough in applying the learning-based method to the end-to-end control of drones, but rarely mention the infrastructure system from simulation to reality. This makes it challenging to reproduce or generalize many research outcomes in real-world scenarios, thereby limiting the practical application of learning-based approaches. To bridge this gap, we propose a system that enables the seamless transfer of end-to-end DRL policies. Our system is built on the open-sourced community and strictly aligned with the real-world system. Besides, we further introduce an intermediate software layer comprising AirGym-Real and control_for_gym, which harmonize sensor data, actuator dynamics, and control interfaces between simulated and real-world domains. It is vital that we utilize a set of skills, including domain randomization, hover throttle alignment, and hierarchical state processing, to enable the seamless policy transfer. Through extensive empirical validation, we demonstrate robust outdoor flight performance under real-world perturbations, including wind gusts and sensor noise, and systematically analyze critical factors—such as domain randomization and observational fidelity—that underpin successful zero-shot transfer. </div><h2 id="motivation" tabindex="-1"><a class="header-anchor" href="#motivation"><span><strong>Motivation</strong></span></a></h2><div class="custom-line-height"> Current works have made a great breakthrough in applying the learning-based method to the end-to-end control of drones, but rarely mention the infrastructure system from simulation to reality. This makes it challenging to reproduce or generalize many research outcomes in real-world scenarios, thereby limiting the practical application of learning-based approaches. <span style="color:pink;"><strong>Therefore, we aim to develop a system that facilitates both training and real-world deployment, minimizing the gap of Sim-to-Real as much as possible for DRL approaches used outside the ideal environments</strong></span>. </div><h2 id="contributions" tabindex="-1"><a class="header-anchor" href="#contributions"><span><strong>Contributions</strong></span></a></h2><div class="vp-steps"><ul><li><div class="custom-line-height"> We demonstrate a comprehensive open-source solution spanning hardware, firmware, and software, from training to deployment. </div></li><li><div class="custom-line-height"> We validate the sim-to-real performance of quadrotor DRL in the wild, using distinct control policies via different hierarchies. The results show the effectiveness of our system.</div></li><li><div class="custom-line-height"> Key factors of transferring a DRL policy to reality outside the laboratory are proposed and discussed. </div></li></ul></div>',8)]))}const d=t(a,[["render",r],["__file","index.html.vue"]]),c=JSON.parse('{"path":"/AirGym/","title":"Demonstrating Sim-to-Real of Reinforcement Learning for Quadrotor System in the Wild","lang":"zh-CN","frontmatter":{"title":"Demonstrating Sim-to-Real of Reinforcement Learning for Quadrotor System in the Wild","createTime":"2025/01/26 22:07:13","permalink":"/AirGym/","description":"Brief: This work is implemented for end-to-end deep reinforcement learning Sim2Real applied on quadrotors. To this end, we develop a series of toolkits including hardware and so...","head":[["meta",{"property":"og:url","content":"https://emnavi.tech/AirGym/"}],["meta",{"property":"og:site_name","content":"emNavi"}],["meta",{"property":"og:title","content":"Demonstrating Sim-to-Real of Reinforcement Learning for Quadrotor System in the Wild"}],["meta",{"property":"og:description","content":"Brief: This work is implemented for end-to-end deep reinforcement learning Sim2Real applied on quadrotors. To this end, we develop a series of toolkits including hardware and so..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-03-28T16:04:35.000Z"}],["meta",{"property":"article:modified_time","content":"2025-03-28T16:04:35.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Demonstrating Sim-to-Real of Reinforcement Learning for Quadrotor System in the Wild\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-03-28T16:04:35.000Z\\",\\"author\\":[]}"]]},"headers":[{"level":2,"title":"Abstract","slug":"abstract","link":"#abstract","children":[]},{"level":2,"title":"Motivation","slug":"motivation","link":"#motivation","children":[]},{"level":2,"title":"Contributions","slug":"contributions","link":"#contributions","children":[]}],"readingTime":{"minutes":1.67,"words":500},"git":{"createdTime":1738167719000,"updatedTime":1743177875000,"contributors":[{"name":"kjaebye","email":"kangyao.huang@outlook.com","commits":3}]},"autoDesc":true,"filePathRelative":"notes/AirGym/README.md"}');export{d as comp,c as data};
